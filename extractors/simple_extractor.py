"""
Simplified Four-LLM Chain Extractor with Conditional Routing
Version: 4.3 - Enhanced Claim Number Extraction
"""
import logging
from typing import Dict, Optional
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_openai import AzureChatOpenAI
from langchain_core.runnables import RunnableLambda, RunnableBranch

from utils.summary_helpers import ensure_date_and_author






logger = logging.getLogger("document_ai")

class SimpleExtractor:
    """
    Smart four-LLM chain extractor with conditional routing:
    1. First LLM: Extract key findings and critical data
    2. Conditional Check: Determine if document has medical content
    3. Second LLM: Generate medical long summary OR Fourth LLM: Generate administrative summary
    4. Third LLM: Generate short summary from long summary
    """
    
    def __init__(self, llm: AzureChatOpenAI):
        self.llm = llm
        self.parser = JsonOutputParser()
        logger.info("âœ… SimpleExtractor v4.3 initialized with Enhanced Claim Number Extraction")
    
    def extract(
        self,
        text: str,
        raw_text: str,
        doc_type: str,
        fallback_date: str
    ) -> Dict:
        """
        Extract document data with FULL CONTEXT using raw text.
        
        Args:
            text: Complete document text (layout-preserved)
            raw_text: Summarized original context from Document AI
            doc_type: Document type
            fallback_date: Fallback date if not found
            
        Returns:
            Dict with long_summary and short_summary
        """
        logger.info("=" * 80)
        logger.info("ðŸ¥ STARTING SIMPLE EXTRACTION (FULL CONTEXT + RAW TEXT)")
        logger.info("=" * 80)
        
        # Check document size
        text_length = len(raw_text)
        token_estimate = text_length // 4
        logger.info(f"ðŸ“„ Document size: {text_length:,} chars (~{token_estimate:,} tokens)")
        
        if token_estimate > 120000:
            logger.warning(f"âš ï¸ Document very large ({token_estimate:,} tokens)")
            logger.warning("âš ï¸ May exceed GPT-4o context window (128K tokens)")
        
        try:
            # STEP 1: Generate long summary with dual-context approach (raw_text + text)
            long_summary = self._generate_long_summary_direct(text, raw_text, doc_type, fallback_date)
            
            # STEP 2: Generate short summary from long summary
            short_summary = self._generate_short_summary_from_long_summary(long_summary, doc_type)
            
            logger.info("=" * 80)
            logger.info("âœ… SIMPLE EXTRACTION COMPLETE (2 LLM CALLS ONLY)")
            logger.info("=" * 80)
            
            return {
                "long_summary": long_summary,
                "short_summary": short_summary,
                "content_type": "universal"
            }
            
        except Exception as e:
            logger.error(f"âŒ Extraction failed: {str(e)}")
            return self._create_error_response(doc_type, str(e), fallback_date)
    
    def _generate_long_summary_direct(self, text: str, raw_text: str, doc_type: str, fallback_date: str) -> str:
        """
        Generate long summary with PRIORITIZED context hierarchy:
        1. PRIMARY SOURCE: raw_text (accurate Document AI summarized context)
        2. SUPPLEMENTARY: text (full OCR extraction for missing details only)
        
        This ensures accurate context preservation while capturing all necessary details.
        """
        logger.info("ðŸ” Processing document with DUAL-CONTEXT approach...")
        logger.info(f"   ðŸ“Œ PRIMARY SOURCE (raw_text): {len(raw_text):,} chars (accurate context)")
        logger.info(f"   ðŸ“„ SUPPLEMENTARY (full text): {len(text):,} chars (detail reference)")
        
        # Build system prompt with CLEAR PRIORITY INSTRUCTIONS
        system_prompt = SystemMessagePromptTemplate.from_template("""
You are a universal medical and administrative document summarization expert analyzing a COMPLETE document.

ðŸŽ¯ CRITICAL CONTEXT HIERARCHY (HIGHEST PRIORITY):

You are provided with TWO versions of the document:

1. **PRIMARY SOURCE - "ACCURATE CONTEXT" (raw_text)**:
   - This is the MOST ACCURATE, context-aware summary generated by Google's Document AI foundation model
   - It has been intelligently processed to preserve CRITICAL CONTEXT
   - **USE THIS AS YOUR PRIMARY SOURCE OF TRUTH**
   - This contains the CORRECT interpretations, accurate findings, and proper context
   - **ALWAYS PRIORITIZE information from this source**

2. **SUPPLEMENTARY SOURCE - "FULL TEXT EXTRACTION" (text)**:
   - This is the complete OCR text extraction (may have formatting noise, OCR artifacts)
   - Use ONLY to fill in SPECIFIC DETAILS that may be missing from the accurate context
   - Examples of acceptable supplementary use:
       * Exact medication dosages if not in primary source
       * Specific claim numbers or identifiers
       * Additional doctor names mentioned
       * Precise dates or measurements
   - **DO NOT let this override the context from the primary source**

âš ï¸ ANTI-HALLUCINATION RULES FOR DUAL-CONTEXT:

1. **CONTEXT PRIORITY ENFORCEMENT**:
   - When both sources provide information about the SAME finding:
     âœ… ALWAYS use interpretation from PRIMARY SOURCE (accurate context)
     âŒ NEVER override with potentially inaccurate full text version

2. **EXTRACT ONLY EXPLICITLY STATED INFORMATION** - Empty if not mentioned
3. **NO ASSUMPTIONS** - Do not infer or add typical values
4. **ADAPT STRUCTURE** - Use medical sections for clinical content, administrative for non-clinical
5. **EMPTY FIELDS BETTER THAN GUESSES** - Omit sections if no data
6. **SIGNATURE EXTRACTION**: Scan both sources for signatures. Identify authors who signed PHYSICALLY or ELECTRONICALLY.
7. **CLAIM NUMBER EXTRACTION**: Scan both sources for claim number. Extract exact value if present.

ðŸ” SPECIAL INSTRUCTIONS FOR PATIENT DETAILS VALIDATION:

**CRITICAL - PATIENT DETAILS CROSS-VALIDATION**:
If the raw_text contains a "--- PATIENT DETAILS ---" section:
1. **FIRST**: Extract the patient details from that section (Patient Name, DOB, DOI, Claim Number)
2. **SECOND**: Cross-validate each detail against the FULL TEXT EXTRACTION (text parameter) as sometimes the full text is not properly formatted, so the fields and values are not aligned properly, but the full text must have the correct details, and if we are getting the pateint details from the patient details section, we need to make sure they are accurate by cross-checking with the full text extraction
3. **VALIDATION RULES**:
   âœ… If the detail MATCHES what's in the full text extraction â†’ USE IT (it's accurate)
   âœ… If the detail is CLOSE but has minor formatting differences â†’ USE the formatted version from patient details section
   âŒ If the detail CONTRADICTS the full text extraction â†’ IGNORE the patient details section value and extract directly from full text
   âŒ If the detail is MISSING or shows "N/A" â†’ Extract directly from full text extraction
4. **FINAL CHECK**: Ensure all patient details (Name, DOB, DOI, Claim Number) are accurate and consistent with the document content

**Example Validation Process**:
- Patient Details section shows: "Patient Name: John Smith"
- Full text contains: "Patient: John Smith" â†’ âœ… VALID - Use "John Smith"
- Patient Details section shows: "DOB: N/A"
- Full text contains: "Date of Birth: 05/15/1975" â†’ âŒ INVALID - Use "05/15/1975" from full text
- Patient Details section shows: "Claim Number: 12345-ABC"
- Full text contains: "Claim #: 12345-ABC" â†’ âœ… VALID - Use "12345-ABC"

UNIVERSAL EXTRACTION FOCUS:

For MEDICAL DOCUMENTS:
I. PATIENT & CLINICAL CONTEXT
II. CRITICAL FINDINGS & DIAGNOSES
III. LAB/IMAGING RESULTS
IV. TREATMENT & OBSERVATIONS
V. STATUS & RECOMMENDATIONS

For ADMINISTRATIVE DOCUMENTS:
I. DOCUMENT OVERVIEW
II. KEY PARTIES & INFORMATION
III. ACTION ITEMS & DEADLINES
IV. CONTACT & FOLLOW-UP

Now analyze this COMPLETE document using the DUAL-CONTEXT approach and generate a COMPREHENSIVE STRUCTURED LONG SUMMARY:
""")

        # User prompt with DUAL-CONTEXT input
        user_prompt = HumanMessagePromptTemplate.from_template("""
DOCUMENT TYPE: {doc_type}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“Œ PRIMARY SOURCE - ACCURATE CONTEXT (USE THIS FIRST):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{primary_source}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“„ SUPPLEMENTARY SOURCE - FULL TEXT (USE ONLY FOR MISSING DETAILS):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{supplementary_source}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

CURRENT DATE: {fallback_date}

**INSTRUCTIONS**: Generate a comprehensive structured summary following the DUAL-CONTEXT hierarchy. Prioritize PRIMARY SOURCE for clinical/administrative context. Use SUPPLEMENTARY SOURCE only for specific details (dosages, claim numbers, exact dates, additional names) not found in PRIMARY SOURCE.

Generate the long summary in this EXACT STRUCTURED FORMAT (adapt to medical or administrative content):

For MEDICAL CONTENT:
ðŸ“‹ MEDICAL DOCUMENT OVERVIEW
--------------------------------------------------
Document Type: {doc_type}
Report Date: [extracted or {fallback_date}]
Claim Number: [extracted if present; otherwise omit]
Patient Name: [extracted]
Provider: [extracted]
                                                         
ðŸ‘¤ PATIENT & CLINICAL INFORMATION
--------------------------------------------------
Name: [extracted]
DOB: [extracted]
Chief Complaint: [extracted]
Clinical History: [extracted]
                                                               
All Doctors Involved:
â€¢ [list all extracted doctors with names and titles]
â”â”â” ALL DOCTORS EXTRACTION â”â”â”
- Extract ALL physician/doctor names mentioned ANYWHERE in both sources.
- Include: consulting doctor, referring doctor, ordering physician, treating physician, examining physician, PCP, specialist, etc.
- Include names with credentials (MD, DO, DPM, DC, NP, PA) or doctor titles (Dr., Doctor).
- Extract ONLY actual person names, NOT pharmacy labels, business names, or generic titles.
- Format: Include titles and credentials as they appear (e.g., "Dr. John Smith, MD", "Jane Doe, DO").
- If no doctors found, leave list empty [].

â”â”â” CLAIM NUMBER EXTRACTION PATTERNS â”â”â”
CRITICAL: Scan BOTH SOURCES (header, footer, cc: lines, letterhead) for claim numbers.

Common claim number patterns (case-insensitive):
- if in the structured raw_text like json formatted dat, if the fileds are first and values then handle the same way to extract the claim number of accurate filed, but most of the time the fields are first and values are second then the claim number will be in the second field
- "[Claim #XXXXXXXXX]" or "[Claim #XXXXX-XXX]"
- "Claim Number: XXXXXXXXX" or "Claim #: XXXXXXXXX"
- "Claim: XXXXXXXXX" or "Claim #XXXXXXXXX"
- "WC Claim: XXXXXXXXX" or "Workers Comp Claim: XXXXXXXXX"
- "Policy/Claim: XXXXXXXXX"
- In "cc:" lines: "Broadspire [Claim #XXXXXXXXX]"
- In subject lines or reference fields: "Claim #XXXXXXX"
                                                               
ðŸš¨ CRITICAL FINDINGS
--------------------------------------------------
â€¢ [list up to 5 critical items from PRIMARY SOURCE]

ðŸ¥ DIAGNOSES & ASSESSMENTS
--------------------------------------------------
Primary Diagnosis: [from PRIMARY SOURCE]
Secondary Diagnoses:
â€¢ [list up to 3 from PRIMARY SOURCE]
Lab Results:
â€¢ [list up to 5 key results from PRIMARY SOURCE]
â€¢ [list key results with values/ranges]
Imaging Findings:
â€¢ [list key observations]

ðŸ’Š TREATMENT & OBSERVATIONS
--------------------------------------------------
Current Medications:
â€¢ [list with doses if stated]
Clinical Observations:
â€¢ [list vital signs, exam findings]
Procedures/Treatments:
â€¢ [list recent or ongoing]

ðŸ’¼ STATUS & RECOMMENDATIONS
--------------------------------------------------
Work Status: [extracted]
MMI: [extracted]
Recommendations:
â€¢ [list up to 5 next steps]

For ADMINISTRATIVE CONTENT:
ðŸ“‹ ADMINISTRATIVE DOCUMENT OVERVIEW
--------------------------------------------------
Document Type: {doc_type}
Document Date: [extracted or {fallback_date}]
Claim Number: [extracted if present; otherwise omit]
Purpose: [extracted]
Author:
hint: check the signature block mainly last pages of the report and the closing statement the person who signed the report either physically or electronically
â€¢ Signature: [extracted name/title if physical signature present or extracted name/title if electronic signature present; otherwise omit ; should not the business name or generic title like "Medical Group" or "Health Services", "Physician", "Surgeon","Pharmacist", "Radiologist", etc.]

ðŸ‘¥ KEY PARTIES
--------------------------------------------------
Patient: [extracted]
Provider: [extracted]
Referring Party: [extracted]

ðŸ“„ KEY INFORMATION
--------------------------------------------------
Important Dates: [extracted]
Reference Numbers: [extracted]
Administrative Details: [extracted]

âœ… ACTION ITEMS
--------------------------------------------------
Required Actions:
â€¢ [list up to 5]
Deadlines: [extracted]

ðŸ“ž CONTACT & FOLLOW-UP
--------------------------------------------------
Contact Information: [extracted]
Next Steps: [extracted]

âš ï¸ MANDATORY EXTRACTION RULES (donot include in output, for LLM use only):
1. Adapt structure to content: Medical if clinical data present, Administrative if not
2. Extract ONLY explicit information - omit sections with no data
3. Use exact wording for medical terms, dates, names, signatures, and claim numbers
4. Bullet points for lists, clear headings
5. No assumptions or additions
6. For signatures: Look for end-of-document sign blocks, /s/ notations, scanned signatures, or explicit "signed by" statements. Distinguish physical (e.g., "Handwritten by Dr. X") vs. electronic (e.g., "Electronically signed by Dr. Y").
7. For claim number: Search for patterns like "Claim #", "Claim Number", "WC Claim", etc., and extract the alphanumeric value exactly.
""")

        chat_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])
        
        try:
            logger.info("ðŸ¤– Invoking LLM for direct full-context universal long summary generation with DUAL-CONTEXT...")
            
            # Single LLM call with DUAL-CONTEXT (primary + supplementary sources)
            chain = chat_prompt | self.llm
            result = chain.invoke({
                "primary_source": raw_text,  # PRIMARY: Document AI summarizer output
                "supplementary_source": text,  # SUPPLEMENTARY: Full OCR text
                "doc_type": doc_type,
                "fallback_date": fallback_date
            })
            
            long_summary = result.content.strip()
            
            logger.info(f"âš¡ Direct universal long summary generation completed with DUAL-CONTEXT")
            logger.info(f"âœ… Generated long summary using:")
            logger.info(f"   - PRIMARY SOURCE: {len(raw_text):,} chars")
            logger.info(f"   - SUPPLEMENTARY SOURCE: {len(text):,} chars")
            
            return long_summary
            
        except Exception as e:
            logger.error(f"âŒ Direct universal long summary generation failed: {e}", exc_info=True)
            
            # Fallback: Generate a minimal summary
            return f"Fallback long summary for {doc_type} on {fallback_date}: Document processing failed due to {str(e)}"

    def _generate_short_summary_from_long_summary(self, long_summary: str, doc_type: str) -> str:
        """
        Generate concise short summary from long summary.
        Enhanced to handle any document type with available information.
        Includes author/signer and claim number but excludes patient details.
        """
        logger.info("ðŸŽ¯ Third LLM - Generating short summary...")
        
        system_prompt = SystemMessagePromptTemplate.from_template("""
You create CONCISE pipe-delimited summaries for ANY type of medical document.
- **ONLY include, critical, or clinically significant findings**.
- **ONLY include abnormalities or pathological findings for physical exam and vital signs (if present). Skip normal findings entirely for these (physical exam, vital signs) fields.**
    

ABSOLUTE RULES - NO EXCEPTIONS:
1. Word count MUST be **between 30 and 60 words**.
2. Output format MUST be pipe-delimited with ONLY fields that have actual data.
3. NEVER output a key if you don't have the value.
4. NEVER output [empty], [unknown], [not provided], [N/A], or ANY placeholder text.
5. NEVER output empty strings, blank values, or null markers.
6. If a field has no real value in the text, DO NOT include that field AT ALL.
7. Skip the entire "Key: Value" segment if no value exists.
- For Author never use "Dr." with it


CRITICAL: If you see terms like "Decision: [empty]" or "Medical Necessity: [empty]" in your output - YOU ARE DOING IT WRONG. Simply don't include those keys.

Possible fields (include ONLY if real data exists; NO need to include patient details like name, DOB, MRN, Claim #, Signature Type etc.):
   - Report Title
   - Author
   - Date
   - Body Parts
   - Diagnosis
   - Physical Exam (only abnormal findings and observations else skip)
   - Vital Signs (key abnormal findings only else skip)
   - Lab Results (key abnormal findings)
   - Imaging Findings (key observations)
   - Medication
   - MMI Status
   - Key Action Items
   - Work Status
   - Recommendation
   - Critical Finding
   - Urgent Next Steps
   - Rationale
   - Treatment Plan
   - Procedure
   - Test Results

***FORMAT RULES***
- Each segment: **Key: Value** (separated by pipes |)
- If NO VALUE exists â†’ SKIP THE ENTIRE SEGMENT
- NEVER output: [empty], [unknown], blank spaces as values
- NEVER produce double pipes (||)
- ONLY include segments with actual, real data
- For Author: Include name with credentials if available, e.g., "Author: Dr. Smith, M.D."

EXAMPLES (reference only - adapt to your document):
                                                                  
general layout:
"[Report Title] | [Author] | [Date] | Body Parts: [value] | Diagnosis: [value] | Physical Exam: [value (only abnormal findings and observations else skip)] | Vital Signs: [value (key abnormal findings only else skip)] | Medication: [value] | MMI Status: [value] | Work Status: [value] | Recommendation: [value] | Critical Finding: [value] | Urgent Next Steps: [value] | Rationale: [value] | Treatment Plan: [value]"

Lab Report with complete data:
"Lab Results | Jones Doe | Date: 10/22/2025 | Critical Finding: Elevated WBC 15.2 (H), Glucose 245 mg/dL (H) | Lab Results: Hemoglobin 12.1, Creatinine 1.2 | Recommendation: Repeat CBC in 1 week, endocrinology consult"

Imaging Report:
"MRI Report | Lee | Date: 09/15/2025 | Body Parts: L4-L5, L5-S1 | Imaging Findings: Moderate central stenosis L4-L5, broad-based disc herniation L5-S1 | Recommendation: Epidural steroid injection, neurosurgery consultation"

Clinical Note with limited data:
"Follow-up Visit | Smith | Date: 08/20/2025 | Body Parts: Right knee | Diagnosis: Post-op ACL reconstruction | Work Status: Modified duty"

Notice: Only fields with actual values are included. No [empty] or placeholder fields.

WHAT NOT TO DO:
âŒ "Report | Dr. Smith | Decision: [empty] | Medical Necessity: [empty]"
âœ… "Report | Smith | Date: 04/13/2017 | Diagnosis: Meniscus tear"

FINAL CHECKLIST BEFORE OUTPUT:
- Does my output contain [empty], [unknown], or any placeholder? â†’ REMOVE THOSE FIELDS
- Does my output have any keys without real values? â†’ REMOVE THOSE KEYS
- Is every field populated with actual information from the text? â†’ YES = GOOD
- Word count between 30-60? â†’ CHECK

Your output must be a SINGLE LINE with ONLY available information in pipe-delimited format.
""")

        user_prompt = HumanMessagePromptTemplate.from_template("""
LONG SUMMARY:
{long_summary}

Create a clean pipe-delimited short summary following these rules:
1. Include ONLY fields that have actual values (no [empty], no placeholders)
2. If a field has no data, skip it entirely - don't include the key
3. Exclude all patient identifying details (name, DOB, MRN, claim number)
4. Keep between 30-60 words
5. Single line, pipe-delimited format

Short summary:
""")
        
        chat_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])
        
        try:
            # Programmatically add missing Date or Author if LLM missed them
            chain = chat_prompt | self.llm
            response = chain.invoke({"long_summary": long_summary[:3000]})
            short_summary = response.content.strip()
            
            short_summary = self._clean_short_summary(short_summary)
            short_summary = self._clean_pipes_from_summary(short_summary)
            
            # Additional safety: Remove any segments with [empty] or similar placeholders
            short_summary = self._remove_empty_segments(short_summary)
            # Programmatically add missing Date or Author if LLM missed them
            short_summary = ensure_date_and_author(short_summary, long_summary)
            word_count = len(short_summary.split())
            logger.info(f"âœ… Short summary: {word_count} words")
            
            # Fallback if too long
            if word_count > 100:
                words = short_summary.split()
                short_summary = ' '.join(words[:100]) + "..."
            
            return short_summary
            
        except Exception as e:
            logger.error(f"âŒ Short summary generation failed: {e}")
            return self._clean_pipes_from_summary(f"Report Title: {doc_type} | Date: Unknown")
    
    def _remove_empty_segments(self, text: str) -> str:
        """
        Remove any segments that contain empty values, placeholders, or unwanted markers.
        """
        # Split by pipe
        segments = text.split('|')
        cleaned_segments = []
        
        # Patterns to detect empty/placeholder values
        empty_patterns = [
            '[empty]', '[unknown]', '[not provided]', '[n/a]', '[na]',
            'unknown', 'not specified', 'not provided', 'not available',
            'not mentioned', 'not stated', 'none', 'n/a', 'na'
        ]
        
        for segment in segments:
            segment = segment.strip()
            if not segment:
                continue
            
            # Check if segment contains a colon (Key: Value format)
            if ':' in segment:
                key, value = segment.split(':', 1)
                value = value.strip()
                
                # Skip if value is empty or matches empty patterns
                if not value:
                    continue
                
                # Check against empty patterns (case-insensitive)
                value_lower = value.lower()
                if any(pattern in value_lower for pattern in empty_patterns):
                    continue
                
                # Keep this segment
                cleaned_segments.append(segment)
            else:
                # If no colon, keep as-is (shouldn't happen but safety)
                cleaned_segments.append(segment)
        
        return ' | '.join(cleaned_segments)
    
    def _clean_empty_fields(self, data: Dict, fallback_date: str) -> Dict:
        """Remove all empty fields and ensure clean structure."""
        cleaned = {}
        
        # Only include patient_details if it has any non-empty values
        if "patient_details" in data:
            patient_clean = {}
            for key, value in data["patient_details"].items():
                if value and str(value).strip():
                    patient_clean[key] = value
            if patient_clean:
                cleaned["patient_details"] = patient_clean
        
        # Only include critical_findings if non-empty
        critical_findings = data.get("critical_findings", [])
        if critical_findings and any(finding and str(finding).strip() for finding in critical_findings):
            cleaned["critical_findings"] = [f for f in critical_findings if f and str(f).strip()]
        
        # Only include diagnoses if non-empty
        diagnoses = data.get("diagnoses", [])
        if diagnoses and any(dx and str(dx).strip() for dx in diagnoses):
            cleaned["diagnoses"] = [dx for dx in diagnoses if dx and str(dx).strip()]
        
        # Only include lab_results if non-empty
        lab_results = data.get("lab_results", [])
        if lab_results and any(lab and str(lab).strip() for lab in lab_results):
            cleaned["lab_results"] = [lab for lab in lab_results if lab and str(lab).strip()]
        
        # Only include imaging_findings if non-empty
        imaging_findings = data.get("imaging_findings", [])
        if imaging_findings and any(img and str(img).strip() for img in imaging_findings):
            cleaned["imaging_findings"] = [img for img in imaging_findings if img and str(img).strip()]
        
        # Only include clinical_observations if non-empty
        clinical_obs = data.get("clinical_observations", [])
        if clinical_obs and any(obs and str(obs).strip() for obs in clinical_obs):
            cleaned["clinical_observations"] = [obs for obs in clinical_obs if obs and str(obs).strip()]
        
        # Only include current_treatment if it has any non-empty values
        if "current_treatment" in data:
            treatment_clean = {}
            for key, items in data["current_treatment"].items():
                if isinstance(items, list):
                    if items and any(item and str(item).strip() for item in items):
                        treatment_clean[key] = [item for item in items if item and str(item).strip()]
                elif items and str(items).strip():
                    treatment_clean[key] = items
            if treatment_clean:
                cleaned["current_treatment"] = treatment_clean
        
        # Only include work_status if it has any non-empty values
        if "work_status" in data:
            work_clean = {}
            for key, value in data["work_status"].items():
                if value and str(value).strip():
                    work_clean[key] = value
            if work_clean:
                cleaned["work_status"] = work_clean
        
        # Always include important_dates with at least report_date
        cleaned["important_dates"] = {
            "report_date": data.get("important_dates", {}).get("report_date") or fallback_date
        }
        # Add other dates only if they exist
        for key in ["examination_date", "follow_up_dates", "service_date", "collection_date"]:
            value = data.get("important_dates", {}).get(key)
            if value and str(value).strip():
                cleaned["important_dates"][key] = value
        
        # Only include document_context if it has any non-empty values
        if "document_context" in data:
            context_clean = {}
            for key, value in data["document_context"].items():
                if value and str(value).strip():
                    context_clean[key] = value
            if context_clean:
                cleaned["document_context"] = context_clean
        
        return cleaned
    
    def _clean_summary_text(self, text: str) -> str:
        """Remove any unwanted phrases from summary text."""
        unwanted_phrases = [
            "unknown", "not specified", "not provided", "none", 
            "no information", "missing", "unavailable", "unspecified",
            "not mentioned", "not available", "not stated"
        ]
        
        cleaned = text
        for phrase in unwanted_phrases:
            cleaned = cleaned.replace(phrase, "")
        
        # Clean up extra spaces but preserve formatting
        lines = cleaned.split('\n')
        cleaned_lines = []
        for line in lines:
            cleaned_line = ' '.join(line.split())
            if cleaned_line.strip():
                cleaned_lines.append(cleaned_line)
        
        return '\n'.join(cleaned_lines)
    
    def _clean_short_summary(self, text: str) -> str:
        """Clean short summary text."""
        # Remove unwanted phrases
        text = self._clean_summary_text(text)
        
        # Clean formatting
        text = ' '.join(text.split())
        text = text.strip('"').strip("'")
        
        return text 
    def _create_basic_medical_summary(self, extracted_data: Dict, doc_type: str) -> str:
        """Create a basic medical summary from extracted data when LLM fails."""
        dates = extracted_data.get("important_dates", {})
        report_date = dates.get("report_date", "")
        
        sections = []
        
        # Header
        header = f"MEDICAL SUMMARY - {doc_type.upper()}"
        if report_date:
            header += f"\nReport Date: {report_date}"
        sections.append(header)
        
        # Patient info
        patient = extracted_data.get("patient_details", {})
        if patient:
            patient_info = ["PATIENT INFORMATION"]
            if patient.get("name"):
                patient_info.append(f"â€¢ Name: {patient['name']}")
            if patient.get("dob"):
                patient_info.append(f"â€¢ DOB: {patient['dob']}")
            if patient.get("mrn"):
                patient_info.append(f"â€¢ MRN: {patient['mrn']}")
            if len(patient_info) > 1:
                sections.append("\n".join(patient_info))
        
        # Lab results
        lab_results = extracted_data.get("lab_results", [])
        if lab_results:
            lab_section = ["LABORATORY RESULTS"]
            for result in lab_results[:10]:
                lab_section.append(f"â€¢ {result}")
            sections.append("\n".join(lab_section))
        
        # Imaging findings
        imaging = extracted_data.get("imaging_findings", [])
        if imaging:
            img_section = ["IMAGING FINDINGS"]
            for finding in imaging[:10]:
                img_section.append(f"â€¢ {finding}")
            sections.append("\n".join(img_section))
        
        # Critical findings
        critical = extracted_data.get("critical_findings", [])
        if critical:
            crit_section = ["CRITICAL FINDINGS"]
            for finding in critical[:5]:
                crit_section.append(f"â€¢ {finding}")
            sections.append("\n".join(crit_section))
        
        if len(sections) > 1:
            return "\n\n".join(sections)
        
        return f"{header}\n\nBasic medical information extracted. Review original document for details."
    
    def _create_basic_administrative_summary(self, extracted_data: Dict, doc_type: str) -> str:
        """Create a basic administrative summary when LLM fails."""
        dates = extracted_data.get("important_dates", {})
        report_date = dates.get("report_date", "")
        
        header = f"ADMINISTRATIVE SUMMARY - {doc_type.upper()}"
        if report_date:
            header += f"\nDocument Date: {report_date}"
        
        return f"{header}\n\nAdministrative document processed. No clinical content identified."
    
    def _clean_pipes_from_summary(self, short_summary: str) -> str:
        """
        Clean empty pipes from short summary to avoid consecutive pipes or trailing pipes.
        """
        if not short_summary or '|' not in short_summary:
            return short_summary
        
        # Split by pipe and clean each part
        parts = short_summary.split('|')
        cleaned_parts = []
        
        for part in parts:
            # Remove whitespace and check if part has meaningful content
            stripped_part = part.strip()
            # Keep part if it has actual content (not just empty or whitespace)
            if stripped_part:
                cleaned_parts.append(stripped_part)
        
        # Join back with pipes - only include parts with actual content
        cleaned_summary = ' | '.join(cleaned_parts)
        
        logger.info(f"ðŸ”§ Pipe cleaning: {len(parts)} parts -> {len(cleaned_parts)} meaningful parts")
        return cleaned_summary
    
    def _create_fallback_extraction(self, fallback_date: str, doc_type: str) -> Dict:
        """Create fallback extraction data with clean empty fields."""
        return {
            "important_dates": {
                "report_date": fallback_date
            }
        }
    
    def _create_error_response(self, doc_type: str, error_msg: str, fallback_date: str) -> Dict:
        """Create error response that still provides a summary."""
        return {
            "long_summary": f"DOCUMENT SUMMARY - {doc_type.upper()}\n\nDocument processed. Basic information extracted.",
            "short_summary": f"Report Title: {doc_type} | Date: {fallback_date}",
            "content_type": "unknown"
        }